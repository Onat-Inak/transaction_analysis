{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from models.LSTM import LSTM\n",
    "from models.RNN import RNN\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import Dataset\n",
    "import os\n",
    "from torchsummary import summary\n",
    "from tools.adjust_learning_rate import adjust_learning_rate\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of negative sequence array (OHE):  (100000, 10, 312)\n",
      "Shape of positive sequence array (OHE):  (11979, 10, 312)\n",
      "Shape of negative sequence array:  (100000, 10)\n",
      "Shape of positive sequence array:  (11979, 10)\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load 3D numpy matrices (user, time, transaction type)\n",
    "ns = np.load('data/neg_sequences.npy')\n",
    "ps = np.load('data/pos_sequences.npy')\n",
    "\n",
    "transaction_size = ns.shape[-1]\n",
    "\n",
    "# Take a look at the given data with OHE (one-hot encodings)\n",
    "print('Shape of negative sequence array (OHE): ', ns.shape)\n",
    "print('Shape of positive sequence array (OHE): ', ps.shape)\n",
    "\n",
    "# Convert one-hot encodings to integers:\n",
    "ns = np.argmax(ns, axis=2)\n",
    "ps = np.argmax(ps, axis=2)\n",
    "\n",
    "# Take a look at the given data\n",
    "print('Shape of negative sequence array: ', ns.shape)\n",
    "print('Shape of positive sequence array: ', ps.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label the data\n",
    "ns_label = np.zeros_like(ns[:,0])\n",
    "ps_label = np.ones_like(ps[:,0])\n",
    "\n",
    "# Concetenate positive sequences with negative sequences regarding users with correponding labels (axis=0)\n",
    "X = np.concatenate((ns, ps), axis=0)\n",
    "y = np.concatenate((ns_label, ps_label), axis=0) \n",
    "\n",
    "# Shuffle data and labels, for reproductivity set random_state=0\n",
    "# dataset, labels = shuffle(dataset, labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train, test and validation ratios\n",
    "train_ratio = 0.8\n",
    "test_ratio = 0.1\n",
    "val_ratio = 0.1\n",
    "\n",
    "# Split the data / Shuffle it and maintain class balance\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_ratio, random_state=42, shuffle=True)\n",
    "\n",
    "# Further split train_data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=val_ratio, random_state=42, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (90702, 10)  - y_train.shape:  (90702,)\n",
      "X_test.shape:  (11198, 10)  - y_test.shape:  (11198,)\n",
      "X_val.shape:  (10079, 10)  - y_val.shape:  (10079,)\n"
     ]
    }
   ],
   "source": [
    "# Print train, test and validation dataset and label shapes\n",
    "print('X_train.shape: ', X_train.shape, ' - y_train.shape: ', y_train.shape)\n",
    "print('X_test.shape: ', X_test.shape, ' - y_test.shape: ', y_test.shape)\n",
    "print('X_val.shape: ', X_val.shape, ' - y_val.shape: ', y_val.shape)\n",
    "\n",
    "# Convert numpy arrays to torch.tensor\n",
    "X_train, y_train = torch.from_numpy(X_train), torch.from_numpy(y_train)\n",
    "X_train, y_train = X_train.to(device, dtype=torch.int32), y_train.to(device, dtype=torch.float32)\n",
    "X_test, y_test = torch.from_numpy(X_test), torch.from_numpy(y_test)\n",
    "X_test, y_test = X_test.to(device, dtype=torch.int32), y_test.to(device, dtype=torch.float32)\n",
    "X_val, y_val = torch.from_numpy(X_val), torch.from_numpy(y_val)\n",
    "X_val, y_val = X_val.to(device, dtype=torch.int32), y_val.to(device, dtype=torch.float32)\n",
    "\n",
    "# Create a custom dataset\n",
    "train_dataset = Dataset(X_train, y_train, device)\n",
    "test_dataset = Dataset(X_test, y_test, device)\n",
    "val_dataset = Dataset(X_val, y_val, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "# Divide train and test dataset into batches\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Check whether data is splitted correctly -> X_.shape: (batch, seq, encoding), y_.shape: (batch)\n",
    "# for i, (X_, y_) in enumerate(train_loader): \n",
    "#     print(X_.shape, y_.shape)\n",
    "#     print(X_[:10,:])\n",
    "#     print(y_[:10])\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN settings\n",
    "embedding_dim = 64\n",
    "hidden_dim = 128\n",
    "num_layers = 1\n",
    "\n",
    "## parameter setting\n",
    "num_epochs = 50\n",
    "learning_rate = 0.01\n",
    "\n",
    "model = RNN(transaction_size, embedding_dim, hidden_dim, num_layers, device, num_classes = 1, batch_first = True, fc_hidden_dim = 128)\n",
    "\n",
    "# for i, (X_, y_) in enumerate(train_loader):\n",
    "#     out = model(X_)\n",
    "#     break\n",
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         # print (name, param.data)\n",
    "#         print (name)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LSTM settings\n",
    "# embedding_dim = 64\n",
    "# hidden_dim = 64\n",
    "# transaction_size = 312\n",
    "# num_layers = 2\n",
    "\n",
    "# # parameter setting\n",
    "# num_epochs = 50\n",
    "# batch_size = 100\n",
    "# use_gpu = (device.type == 'cuda')\n",
    "# learning_rate = 0.01\n",
    "\n",
    "# # Divide training dataset into batches\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# # Check whether data is splitted correctly -> X_.shape: (batch, seq, encoding), y_.shape: (batch)\n",
    "# for i, (X_, y_) in enumerate(train_loader): \n",
    "#     print(X_.shape, y_.shape)\n",
    "#     print(i)\n",
    "\n",
    "# model = LSTM(embedding_dim, hidden_dim, transaction_size, num_layers, batch_size, use_gpu)\n",
    "\n",
    "# model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 0.010000\n",
      "Epoch [1/50], Step [100/908], Loss: 0.2919\n",
      "Epoch [1/50], Step [200/908], Loss: 0.2504\n",
      "Epoch [1/50], Step [300/908], Loss: 0.2443\n",
      "Epoch [1/50], Step [400/908], Loss: 0.2455\n",
      "Epoch [1/50], Step [500/908], Loss: 0.2490\n",
      "Epoch [1/50], Step [600/908], Loss: 0.2369\n",
      "Epoch [1/50], Step [700/908], Loss: 0.2391\n",
      "Epoch [1/50], Step [800/908], Loss: 0.2339\n",
      "Epoch [1/50], Step [900/908], Loss: 0.2452\n",
      "learning_rate: 0.010000\n",
      "Epoch [2/50], Step [100/908], Loss: 0.2650\n",
      "Epoch [2/50], Step [200/908], Loss: 0.2298\n",
      "Epoch [2/50], Step [300/908], Loss: 0.2338\n",
      "Epoch [2/50], Step [400/908], Loss: 0.2402\n",
      "Epoch [2/50], Step [500/908], Loss: 0.2456\n",
      "Epoch [2/50], Step [600/908], Loss: 0.2294\n",
      "Epoch [2/50], Step [700/908], Loss: 0.2346\n",
      "Epoch [2/50], Step [800/908], Loss: 0.2301\n",
      "Epoch [2/50], Step [900/908], Loss: 0.2430\n",
      "learning_rate: 0.010000\n",
      "Epoch [3/50], Step [100/908], Loss: 0.2615\n",
      "Epoch [3/50], Step [200/908], Loss: 0.2293\n",
      "Epoch [3/50], Step [300/908], Loss: 0.2301\n",
      "Epoch [3/50], Step [400/908], Loss: 0.2334\n",
      "Epoch [3/50], Step [500/908], Loss: 0.2343\n",
      "Epoch [3/50], Step [600/908], Loss: 0.2249\n",
      "Epoch [3/50], Step [700/908], Loss: 0.2322\n",
      "Epoch [3/50], Step [800/908], Loss: 0.2365\n",
      "Epoch [3/50], Step [900/908], Loss: 0.2590\n",
      "learning_rate: 0.010000\n",
      "Epoch [4/50], Step [100/908], Loss: 0.2700\n",
      "Epoch [4/50], Step [200/908], Loss: 0.2333\n",
      "Epoch [4/50], Step [300/908], Loss: 0.2328\n",
      "Epoch [4/50], Step [400/908], Loss: 0.2355\n",
      "Epoch [4/50], Step [500/908], Loss: 0.2351\n",
      "Epoch [4/50], Step [600/908], Loss: 0.2272\n",
      "Epoch [4/50], Step [700/908], Loss: 0.2349\n",
      "Epoch [4/50], Step [800/908], Loss: 0.2324\n",
      "Epoch [4/50], Step [900/908], Loss: 0.2426\n",
      "learning_rate: 0.010000\n",
      "Epoch [5/50], Step [100/908], Loss: 0.2659\n",
      "Epoch [5/50], Step [200/908], Loss: 0.2321\n",
      "Epoch [5/50], Step [300/908], Loss: 0.2343\n",
      "Epoch [5/50], Step [400/908], Loss: 0.2379\n",
      "Epoch [5/50], Step [500/908], Loss: 0.2357\n",
      "Epoch [5/50], Step [600/908], Loss: 0.2271\n",
      "Epoch [5/50], Step [700/908], Loss: 0.2383\n",
      "Epoch [5/50], Step [800/908], Loss: 0.2257\n",
      "Epoch [5/50], Step [900/908], Loss: 0.2391\n",
      "learning_rate: 0.010000\n",
      "Epoch [6/50], Step [100/908], Loss: 0.2643\n",
      "Epoch [6/50], Step [200/908], Loss: 0.2291\n",
      "Epoch [6/50], Step [300/908], Loss: 0.2358\n",
      "Epoch [6/50], Step [400/908], Loss: 0.2361\n",
      "Epoch [6/50], Step [500/908], Loss: 0.2360\n",
      "Epoch [6/50], Step [600/908], Loss: 0.2286\n",
      "Epoch [6/50], Step [700/908], Loss: 0.2341\n",
      "Epoch [6/50], Step [800/908], Loss: 0.2255\n",
      "Epoch [6/50], Step [900/908], Loss: 0.2394\n",
      "learning_rate: 0.010000\n",
      "Epoch [7/50], Step [100/908], Loss: 0.2569\n",
      "Epoch [7/50], Step [200/908], Loss: 0.2257\n",
      "Epoch [7/50], Step [300/908], Loss: 0.2341\n",
      "Epoch [7/50], Step [400/908], Loss: 0.2340\n",
      "Epoch [7/50], Step [500/908], Loss: 0.2362\n",
      "Epoch [7/50], Step [600/908], Loss: 0.2242\n",
      "Epoch [7/50], Step [700/908], Loss: 0.2340\n",
      "Epoch [7/50], Step [800/908], Loss: 0.2268\n",
      "Epoch [7/50], Step [900/908], Loss: 0.2389\n",
      "learning_rate: 0.010000\n",
      "Epoch [8/50], Step [100/908], Loss: 0.2589\n",
      "Epoch [8/50], Step [200/908], Loss: 0.2267\n",
      "Epoch [8/50], Step [300/908], Loss: 0.2257\n",
      "Epoch [8/50], Step [400/908], Loss: 0.2318\n",
      "Epoch [8/50], Step [500/908], Loss: 0.2341\n",
      "Epoch [8/50], Step [600/908], Loss: 0.2236\n",
      "Epoch [8/50], Step [700/908], Loss: 0.2303\n",
      "Epoch [8/50], Step [800/908], Loss: 0.2244\n",
      "Epoch [8/50], Step [900/908], Loss: 0.2370\n",
      "learning_rate: 0.010000\n",
      "Epoch [9/50], Step [100/908], Loss: 0.2615\n",
      "Epoch [9/50], Step [200/908], Loss: 0.2278\n",
      "Epoch [9/50], Step [300/908], Loss: 0.2250\n",
      "Epoch [9/50], Step [400/908], Loss: 0.2316\n",
      "Epoch [9/50], Step [500/908], Loss: 0.2318\n",
      "Epoch [9/50], Step [600/908], Loss: 0.2229\n",
      "Epoch [9/50], Step [700/908], Loss: 0.2315\n",
      "Epoch [9/50], Step [800/908], Loss: 0.2224\n",
      "Epoch [9/50], Step [900/908], Loss: 0.2388\n",
      "learning_rate: 0.010000\n",
      "Epoch [10/50], Step [100/908], Loss: 0.2587\n",
      "Epoch [10/50], Step [200/908], Loss: 0.2272\n",
      "Epoch [10/50], Step [300/908], Loss: 0.2289\n",
      "Epoch [10/50], Step [400/908], Loss: 0.2322\n",
      "Epoch [10/50], Step [500/908], Loss: 0.2328\n",
      "Epoch [10/50], Step [600/908], Loss: 0.2199\n",
      "Epoch [10/50], Step [700/908], Loss: 0.2299\n",
      "Epoch [10/50], Step [800/908], Loss: 0.2241\n",
      "Epoch [10/50], Step [900/908], Loss: 0.2427\n",
      "learning_rate: 0.001000\n",
      "Epoch [11/50], Step [100/908], Loss: 0.2559\n",
      "Epoch [11/50], Step [200/908], Loss: 0.2342\n",
      "Epoch [11/50], Step [300/908], Loss: 0.2260\n",
      "Epoch [11/50], Step [400/908], Loss: 0.2269\n",
      "Epoch [11/50], Step [500/908], Loss: 0.2290\n",
      "Epoch [11/50], Step [600/908], Loss: 0.2175\n",
      "Epoch [11/50], Step [700/908], Loss: 0.2251\n",
      "Epoch [11/50], Step [800/908], Loss: 0.2163\n",
      "Epoch [11/50], Step [900/908], Loss: 0.2326\n",
      "learning_rate: 0.001000\n",
      "Epoch [12/50], Step [100/908], Loss: 0.2496\n",
      "Epoch [12/50], Step [200/908], Loss: 0.2217\n",
      "Epoch [12/50], Step [300/908], Loss: 0.2221\n",
      "Epoch [12/50], Step [400/908], Loss: 0.2246\n",
      "Epoch [12/50], Step [500/908], Loss: 0.2250\n",
      "Epoch [12/50], Step [600/908], Loss: 0.2157\n",
      "Epoch [12/50], Step [700/908], Loss: 0.2242\n",
      "Epoch [12/50], Step [800/908], Loss: 0.2150\n",
      "Epoch [12/50], Step [900/908], Loss: 0.2311\n",
      "learning_rate: 0.001000\n",
      "Epoch [13/50], Step [100/908], Loss: 0.2504\n",
      "Epoch [13/50], Step [200/908], Loss: 0.2203\n",
      "Epoch [13/50], Step [300/908], Loss: 0.2214\n",
      "Epoch [13/50], Step [400/908], Loss: 0.2229\n",
      "Epoch [13/50], Step [500/908], Loss: 0.2238\n",
      "Epoch [13/50], Step [600/908], Loss: 0.2141\n",
      "Epoch [13/50], Step [700/908], Loss: 0.2233\n",
      "Epoch [13/50], Step [800/908], Loss: 0.2139\n",
      "Epoch [13/50], Step [900/908], Loss: 0.2303\n",
      "learning_rate: 0.001000\n",
      "Epoch [14/50], Step [100/908], Loss: 0.2483\n",
      "Epoch [14/50], Step [200/908], Loss: 0.2203\n",
      "Epoch [14/50], Step [300/908], Loss: 0.2199\n",
      "Epoch [14/50], Step [400/908], Loss: 0.2223\n",
      "Epoch [14/50], Step [500/908], Loss: 0.2231\n",
      "Epoch [14/50], Step [600/908], Loss: 0.2136\n",
      "Epoch [14/50], Step [700/908], Loss: 0.2213\n",
      "Epoch [14/50], Step [800/908], Loss: 0.2130\n",
      "Epoch [14/50], Step [900/908], Loss: 0.2290\n",
      "learning_rate: 0.001000\n",
      "Epoch [15/50], Step [100/908], Loss: 0.2471\n",
      "Epoch [15/50], Step [200/908], Loss: 0.2191\n",
      "Epoch [15/50], Step [300/908], Loss: 0.2191\n",
      "Epoch [15/50], Step [400/908], Loss: 0.2210\n",
      "Epoch [15/50], Step [500/908], Loss: 0.2226\n",
      "Epoch [15/50], Step [600/908], Loss: 0.2130\n",
      "Epoch [15/50], Step [700/908], Loss: 0.2211\n",
      "Epoch [15/50], Step [800/908], Loss: 0.2131\n",
      "Epoch [15/50], Step [900/908], Loss: 0.2286\n",
      "learning_rate: 0.001000\n",
      "Epoch [16/50], Step [100/908], Loss: 0.2454\n",
      "Epoch [16/50], Step [200/908], Loss: 0.2188\n",
      "Epoch [16/50], Step [300/908], Loss: 0.2194\n",
      "Epoch [16/50], Step [400/908], Loss: 0.2209\n",
      "Epoch [16/50], Step [500/908], Loss: 0.2215\n",
      "Epoch [16/50], Step [600/908], Loss: 0.2116\n",
      "Epoch [16/50], Step [700/908], Loss: 0.2202\n",
      "Epoch [16/50], Step [800/908], Loss: 0.2119\n",
      "Epoch [16/50], Step [900/908], Loss: 0.2280\n",
      "learning_rate: 0.001000\n",
      "Epoch [17/50], Step [100/908], Loss: 0.2443\n",
      "Epoch [17/50], Step [200/908], Loss: 0.2185\n",
      "Epoch [17/50], Step [300/908], Loss: 0.2190\n",
      "Epoch [17/50], Step [400/908], Loss: 0.2208\n",
      "Epoch [17/50], Step [500/908], Loss: 0.2217\n",
      "Epoch [17/50], Step [600/908], Loss: 0.2112\n",
      "Epoch [17/50], Step [700/908], Loss: 0.2202\n",
      "Epoch [17/50], Step [800/908], Loss: 0.2120\n",
      "Epoch [17/50], Step [900/908], Loss: 0.2289\n",
      "learning_rate: 0.001000\n",
      "Epoch [18/50], Step [100/908], Loss: 0.2445\n",
      "Epoch [18/50], Step [200/908], Loss: 0.2191\n",
      "Epoch [18/50], Step [300/908], Loss: 0.2185\n",
      "Epoch [18/50], Step [400/908], Loss: 0.2201\n",
      "Epoch [18/50], Step [500/908], Loss: 0.2210\n",
      "Epoch [18/50], Step [600/908], Loss: 0.2117\n",
      "Epoch [18/50], Step [700/908], Loss: 0.2199\n",
      "Epoch [18/50], Step [800/908], Loss: 0.2115\n",
      "Epoch [18/50], Step [900/908], Loss: 0.2270\n",
      "learning_rate: 0.001000\n",
      "Epoch [19/50], Step [100/908], Loss: 0.2447\n",
      "Epoch [19/50], Step [200/908], Loss: 0.2167\n",
      "Epoch [19/50], Step [300/908], Loss: 0.2175\n",
      "Epoch [19/50], Step [400/908], Loss: 0.2193\n",
      "Epoch [19/50], Step [500/908], Loss: 0.2205\n",
      "Epoch [19/50], Step [600/908], Loss: 0.2106\n",
      "Epoch [19/50], Step [700/908], Loss: 0.2195\n",
      "Epoch [19/50], Step [800/908], Loss: 0.2105\n",
      "Epoch [19/50], Step [900/908], Loss: 0.2266\n",
      "learning_rate: 0.001000\n",
      "Epoch [20/50], Step [100/908], Loss: 0.2437\n",
      "Epoch [20/50], Step [200/908], Loss: 0.2173\n",
      "Epoch [20/50], Step [300/908], Loss: 0.2168\n",
      "Epoch [20/50], Step [400/908], Loss: 0.2193\n",
      "Epoch [20/50], Step [500/908], Loss: 0.2211\n",
      "Epoch [20/50], Step [600/908], Loss: 0.2103\n",
      "Epoch [20/50], Step [700/908], Loss: 0.2189\n",
      "Epoch [20/50], Step [800/908], Loss: 0.2100\n",
      "Epoch [20/50], Step [900/908], Loss: 0.2260\n",
      "learning_rate: 0.000100\n",
      "Epoch [21/50], Step [100/908], Loss: 0.2431\n",
      "Epoch [21/50], Step [200/908], Loss: 0.2151\n",
      "Epoch [21/50], Step [300/908], Loss: 0.2150\n",
      "Epoch [21/50], Step [400/908], Loss: 0.2172\n",
      "Epoch [21/50], Step [500/908], Loss: 0.2189\n",
      "Epoch [21/50], Step [600/908], Loss: 0.2089\n",
      "Epoch [21/50], Step [700/908], Loss: 0.2166\n",
      "Epoch [21/50], Step [800/908], Loss: 0.2066\n",
      "Epoch [21/50], Step [900/908], Loss: 0.2226\n",
      "learning_rate: 0.000100\n",
      "Epoch [22/50], Step [100/908], Loss: 0.2417\n",
      "Epoch [22/50], Step [200/908], Loss: 0.2139\n",
      "Epoch [22/50], Step [300/908], Loss: 0.2145\n",
      "Epoch [22/50], Step [400/908], Loss: 0.2168\n",
      "Epoch [22/50], Step [500/908], Loss: 0.2177\n",
      "Epoch [22/50], Step [600/908], Loss: 0.2082\n",
      "Epoch [22/50], Step [700/908], Loss: 0.2158\n",
      "Epoch [22/50], Step [800/908], Loss: 0.2060\n",
      "Epoch [22/50], Step [900/908], Loss: 0.2220\n",
      "learning_rate: 0.000100\n",
      "Epoch [23/50], Step [100/908], Loss: 0.2409\n",
      "Epoch [23/50], Step [200/908], Loss: 0.2133\n",
      "Epoch [23/50], Step [300/908], Loss: 0.2139\n",
      "Epoch [23/50], Step [400/908], Loss: 0.2160\n",
      "Epoch [23/50], Step [500/908], Loss: 0.2171\n",
      "Epoch [23/50], Step [600/908], Loss: 0.2076\n",
      "Epoch [23/50], Step [700/908], Loss: 0.2154\n",
      "Epoch [23/50], Step [800/908], Loss: 0.2055\n",
      "Epoch [23/50], Step [900/908], Loss: 0.2215\n",
      "learning_rate: 0.000100\n",
      "Epoch [24/50], Step [100/908], Loss: 0.2404\n",
      "Epoch [24/50], Step [200/908], Loss: 0.2127\n",
      "Epoch [24/50], Step [300/908], Loss: 0.2135\n",
      "Epoch [24/50], Step [400/908], Loss: 0.2155\n",
      "Epoch [24/50], Step [500/908], Loss: 0.2167\n",
      "Epoch [24/50], Step [600/908], Loss: 0.2071\n",
      "Epoch [24/50], Step [700/908], Loss: 0.2152\n",
      "Epoch [24/50], Step [800/908], Loss: 0.2051\n",
      "Epoch [24/50], Step [900/908], Loss: 0.2213\n",
      "learning_rate: 0.000100\n",
      "Epoch [25/50], Step [100/908], Loss: 0.2398\n",
      "Epoch [25/50], Step [200/908], Loss: 0.2123\n",
      "Epoch [25/50], Step [300/908], Loss: 0.2131\n",
      "Epoch [25/50], Step [400/908], Loss: 0.2150\n",
      "Epoch [25/50], Step [500/908], Loss: 0.2163\n",
      "Epoch [25/50], Step [600/908], Loss: 0.2068\n",
      "Epoch [25/50], Step [700/908], Loss: 0.2148\n",
      "Epoch [25/50], Step [800/908], Loss: 0.2047\n",
      "Epoch [25/50], Step [900/908], Loss: 0.2210\n",
      "learning_rate: 0.000100\n",
      "Epoch [26/50], Step [100/908], Loss: 0.2395\n",
      "Epoch [26/50], Step [200/908], Loss: 0.2121\n",
      "Epoch [26/50], Step [300/908], Loss: 0.2129\n",
      "Epoch [26/50], Step [400/908], Loss: 0.2146\n",
      "Epoch [26/50], Step [500/908], Loss: 0.2160\n",
      "Epoch [26/50], Step [600/908], Loss: 0.2065\n",
      "Epoch [26/50], Step [700/908], Loss: 0.2144\n",
      "Epoch [26/50], Step [800/908], Loss: 0.2045\n",
      "Epoch [26/50], Step [900/908], Loss: 0.2206\n",
      "learning_rate: 0.000100\n",
      "Epoch [27/50], Step [100/908], Loss: 0.2392\n",
      "Epoch [27/50], Step [200/908], Loss: 0.2117\n",
      "Epoch [27/50], Step [300/908], Loss: 0.2126\n",
      "Epoch [27/50], Step [400/908], Loss: 0.2142\n",
      "Epoch [27/50], Step [500/908], Loss: 0.2157\n",
      "Epoch [27/50], Step [600/908], Loss: 0.2062\n",
      "Epoch [27/50], Step [700/908], Loss: 0.2141\n",
      "Epoch [27/50], Step [800/908], Loss: 0.2041\n",
      "Epoch [27/50], Step [900/908], Loss: 0.2204\n",
      "learning_rate: 0.000100\n",
      "Epoch [28/50], Step [100/908], Loss: 0.2388\n",
      "Epoch [28/50], Step [200/908], Loss: 0.2113\n",
      "Epoch [28/50], Step [300/908], Loss: 0.2122\n",
      "Epoch [28/50], Step [400/908], Loss: 0.2138\n",
      "Epoch [28/50], Step [500/908], Loss: 0.2152\n",
      "Epoch [28/50], Step [600/908], Loss: 0.2058\n",
      "Epoch [28/50], Step [700/908], Loss: 0.2141\n",
      "Epoch [28/50], Step [800/908], Loss: 0.2038\n",
      "Epoch [28/50], Step [900/908], Loss: 0.2202\n",
      "learning_rate: 0.000100\n",
      "Epoch [29/50], Step [100/908], Loss: 0.2383\n",
      "Epoch [29/50], Step [200/908], Loss: 0.2110\n",
      "Epoch [29/50], Step [300/908], Loss: 0.2119\n",
      "Epoch [29/50], Step [400/908], Loss: 0.2136\n",
      "Epoch [29/50], Step [500/908], Loss: 0.2148\n",
      "Epoch [29/50], Step [600/908], Loss: 0.2054\n",
      "Epoch [29/50], Step [700/908], Loss: 0.2137\n",
      "Epoch [29/50], Step [800/908], Loss: 0.2035\n",
      "Epoch [29/50], Step [900/908], Loss: 0.2199\n",
      "learning_rate: 0.000100\n",
      "Epoch [30/50], Step [100/908], Loss: 0.2379\n",
      "Epoch [30/50], Step [200/908], Loss: 0.2109\n",
      "Epoch [30/50], Step [300/908], Loss: 0.2116\n",
      "Epoch [30/50], Step [400/908], Loss: 0.2134\n",
      "Epoch [30/50], Step [500/908], Loss: 0.2146\n",
      "Epoch [30/50], Step [600/908], Loss: 0.2050\n",
      "Epoch [30/50], Step [700/908], Loss: 0.2136\n",
      "Epoch [30/50], Step [800/908], Loss: 0.2032\n",
      "Epoch [30/50], Step [900/908], Loss: 0.2197\n",
      "learning_rate: 0.000010\n",
      "Epoch [31/50], Step [100/908], Loss: 0.2376\n",
      "Epoch [31/50], Step [200/908], Loss: 0.2107\n",
      "Epoch [31/50], Step [300/908], Loss: 0.2112\n",
      "Epoch [31/50], Step [400/908], Loss: 0.2128\n",
      "Epoch [31/50], Step [500/908], Loss: 0.2140\n",
      "Epoch [31/50], Step [600/908], Loss: 0.2047\n",
      "Epoch [31/50], Step [700/908], Loss: 0.2130\n",
      "Epoch [31/50], Step [800/908], Loss: 0.2026\n",
      "Epoch [31/50], Step [900/908], Loss: 0.2187\n",
      "learning_rate: 0.000010\n",
      "Epoch [32/50], Step [100/908], Loss: 0.2375\n",
      "Epoch [32/50], Step [200/908], Loss: 0.2105\n",
      "Epoch [32/50], Step [300/908], Loss: 0.2111\n",
      "Epoch [32/50], Step [400/908], Loss: 0.2127\n",
      "Epoch [32/50], Step [500/908], Loss: 0.2139\n",
      "Epoch [32/50], Step [600/908], Loss: 0.2045\n",
      "Epoch [32/50], Step [700/908], Loss: 0.2129\n",
      "Epoch [32/50], Step [800/908], Loss: 0.2025\n",
      "Epoch [32/50], Step [900/908], Loss: 0.2187\n",
      "learning_rate: 0.000010\n",
      "Epoch [33/50], Step [100/908], Loss: 0.2374\n",
      "Epoch [33/50], Step [200/908], Loss: 0.2103\n",
      "Epoch [33/50], Step [300/908], Loss: 0.2111\n",
      "Epoch [33/50], Step [400/908], Loss: 0.2126\n",
      "Epoch [33/50], Step [500/908], Loss: 0.2139\n",
      "Epoch [33/50], Step [600/908], Loss: 0.2044\n",
      "Epoch [33/50], Step [700/908], Loss: 0.2128\n",
      "Epoch [33/50], Step [800/908], Loss: 0.2024\n",
      "Epoch [33/50], Step [900/908], Loss: 0.2187\n",
      "learning_rate: 0.000010\n",
      "Epoch [34/50], Step [100/908], Loss: 0.2373\n",
      "Epoch [34/50], Step [200/908], Loss: 0.2102\n",
      "Epoch [34/50], Step [300/908], Loss: 0.2110\n",
      "Epoch [34/50], Step [400/908], Loss: 0.2125\n",
      "Epoch [34/50], Step [500/908], Loss: 0.2138\n",
      "Epoch [34/50], Step [600/908], Loss: 0.2043\n",
      "Epoch [34/50], Step [700/908], Loss: 0.2128\n",
      "Epoch [34/50], Step [800/908], Loss: 0.2024\n",
      "Epoch [34/50], Step [900/908], Loss: 0.2187\n",
      "learning_rate: 0.000010\n",
      "Epoch [35/50], Step [100/908], Loss: 0.2372\n",
      "Epoch [35/50], Step [200/908], Loss: 0.2102\n",
      "Epoch [35/50], Step [300/908], Loss: 0.2109\n",
      "Epoch [35/50], Step [400/908], Loss: 0.2124\n",
      "Epoch [35/50], Step [500/908], Loss: 0.2137\n",
      "Epoch [35/50], Step [600/908], Loss: 0.2043\n",
      "Epoch [35/50], Step [700/908], Loss: 0.2127\n",
      "Epoch [35/50], Step [800/908], Loss: 0.2024\n",
      "Epoch [35/50], Step [900/908], Loss: 0.2187\n",
      "learning_rate: 0.000010\n",
      "Epoch [36/50], Step [100/908], Loss: 0.2371\n",
      "Epoch [36/50], Step [200/908], Loss: 0.2101\n",
      "Epoch [36/50], Step [300/908], Loss: 0.2108\n",
      "Epoch [36/50], Step [400/908], Loss: 0.2124\n",
      "Epoch [36/50], Step [500/908], Loss: 0.2137\n",
      "Epoch [36/50], Step [600/908], Loss: 0.2042\n",
      "Epoch [36/50], Step [700/908], Loss: 0.2127\n",
      "Epoch [36/50], Step [800/908], Loss: 0.2023\n",
      "Epoch [36/50], Step [900/908], Loss: 0.2186\n",
      "learning_rate: 0.000010\n",
      "Epoch [37/50], Step [100/908], Loss: 0.2370\n",
      "Epoch [37/50], Step [200/908], Loss: 0.2100\n",
      "Epoch [37/50], Step [300/908], Loss: 0.2108\n",
      "Epoch [37/50], Step [400/908], Loss: 0.2123\n",
      "Epoch [37/50], Step [500/908], Loss: 0.2136\n",
      "Epoch [37/50], Step [600/908], Loss: 0.2042\n",
      "Epoch [37/50], Step [700/908], Loss: 0.2126\n",
      "Epoch [37/50], Step [800/908], Loss: 0.2023\n",
      "Epoch [37/50], Step [900/908], Loss: 0.2186\n",
      "learning_rate: 0.000010\n",
      "Epoch [38/50], Step [100/908], Loss: 0.2370\n",
      "Epoch [38/50], Step [200/908], Loss: 0.2100\n",
      "Epoch [38/50], Step [300/908], Loss: 0.2107\n",
      "Epoch [38/50], Step [400/908], Loss: 0.2123\n",
      "Epoch [38/50], Step [500/908], Loss: 0.2136\n",
      "Epoch [38/50], Step [600/908], Loss: 0.2041\n",
      "Epoch [38/50], Step [700/908], Loss: 0.2126\n",
      "Epoch [38/50], Step [800/908], Loss: 0.2022\n",
      "Epoch [38/50], Step [900/908], Loss: 0.2186\n",
      "learning_rate: 0.000010\n",
      "Epoch [39/50], Step [100/908], Loss: 0.2369\n",
      "Epoch [39/50], Step [200/908], Loss: 0.2099\n",
      "Epoch [39/50], Step [300/908], Loss: 0.2106\n",
      "Epoch [39/50], Step [400/908], Loss: 0.2122\n",
      "Epoch [39/50], Step [500/908], Loss: 0.2136\n",
      "Epoch [39/50], Step [600/908], Loss: 0.2041\n",
      "Epoch [39/50], Step [700/908], Loss: 0.2126\n",
      "Epoch [39/50], Step [800/908], Loss: 0.2022\n",
      "Epoch [39/50], Step [900/908], Loss: 0.2185\n",
      "learning_rate: 0.000010\n",
      "Epoch [40/50], Step [100/908], Loss: 0.2368\n",
      "Epoch [40/50], Step [200/908], Loss: 0.2099\n",
      "Epoch [40/50], Step [300/908], Loss: 0.2106\n",
      "Epoch [40/50], Step [400/908], Loss: 0.2122\n",
      "Epoch [40/50], Step [500/908], Loss: 0.2137\n",
      "Epoch [40/50], Step [600/908], Loss: 0.2040\n",
      "Epoch [40/50], Step [700/908], Loss: 0.2125\n",
      "Epoch [40/50], Step [800/908], Loss: 0.2021\n",
      "Epoch [40/50], Step [900/908], Loss: 0.2185\n",
      "learning_rate: 0.000001\n",
      "Epoch [41/50], Step [100/908], Loss: 0.2368\n",
      "Epoch [41/50], Step [200/908], Loss: 0.2098\n",
      "Epoch [41/50], Step [300/908], Loss: 0.2105\n",
      "Epoch [41/50], Step [400/908], Loss: 0.2121\n",
      "Epoch [41/50], Step [500/908], Loss: 0.2136\n",
      "Epoch [41/50], Step [600/908], Loss: 0.2039\n",
      "Epoch [41/50], Step [700/908], Loss: 0.2124\n",
      "Epoch [41/50], Step [800/908], Loss: 0.2020\n",
      "Epoch [41/50], Step [900/908], Loss: 0.2184\n",
      "learning_rate: 0.000001\n",
      "Epoch [42/50], Step [100/908], Loss: 0.2368\n",
      "Epoch [42/50], Step [200/908], Loss: 0.2098\n",
      "Epoch [42/50], Step [300/908], Loss: 0.2105\n",
      "Epoch [42/50], Step [400/908], Loss: 0.2121\n",
      "Epoch [42/50], Step [500/908], Loss: 0.2136\n",
      "Epoch [42/50], Step [600/908], Loss: 0.2039\n",
      "Epoch [42/50], Step [700/908], Loss: 0.2124\n",
      "Epoch [42/50], Step [800/908], Loss: 0.2020\n",
      "Epoch [42/50], Step [900/908], Loss: 0.2184\n",
      "learning_rate: 0.000001\n",
      "Epoch [43/50], Step [100/908], Loss: 0.2368\n",
      "Epoch [43/50], Step [200/908], Loss: 0.2098\n",
      "Epoch [43/50], Step [300/908], Loss: 0.2105\n",
      "Epoch [43/50], Step [400/908], Loss: 0.2121\n",
      "Epoch [43/50], Step [500/908], Loss: 0.2136\n",
      "Epoch [43/50], Step [600/908], Loss: 0.2039\n",
      "Epoch [43/50], Step [700/908], Loss: 0.2124\n",
      "Epoch [43/50], Step [800/908], Loss: 0.2020\n",
      "Epoch [43/50], Step [900/908], Loss: 0.2184\n",
      "learning_rate: 0.000001\n",
      "Epoch [44/50], Step [100/908], Loss: 0.2368\n",
      "Epoch [44/50], Step [200/908], Loss: 0.2098\n",
      "Epoch [44/50], Step [300/908], Loss: 0.2105\n",
      "Epoch [44/50], Step [400/908], Loss: 0.2121\n",
      "Epoch [44/50], Step [500/908], Loss: 0.2136\n",
      "Epoch [44/50], Step [600/908], Loss: 0.2039\n",
      "Epoch [44/50], Step [700/908], Loss: 0.2124\n",
      "Epoch [44/50], Step [800/908], Loss: 0.2020\n",
      "Epoch [44/50], Step [900/908], Loss: 0.2184\n",
      "learning_rate: 0.000001\n",
      "Epoch [45/50], Step [100/908], Loss: 0.2368\n",
      "Epoch [45/50], Step [200/908], Loss: 0.2098\n",
      "Epoch [45/50], Step [300/908], Loss: 0.2105\n",
      "Epoch [45/50], Step [400/908], Loss: 0.2121\n",
      "Epoch [45/50], Step [500/908], Loss: 0.2136\n",
      "Epoch [45/50], Step [600/908], Loss: 0.2039\n",
      "Epoch [45/50], Step [700/908], Loss: 0.2124\n",
      "Epoch [45/50], Step [800/908], Loss: 0.2020\n",
      "Epoch [45/50], Step [900/908], Loss: 0.2184\n",
      "learning_rate: 0.000001\n",
      "Epoch [46/50], Step [100/908], Loss: 0.2367\n",
      "Epoch [46/50], Step [200/908], Loss: 0.2098\n",
      "Epoch [46/50], Step [300/908], Loss: 0.2105\n",
      "Epoch [46/50], Step [400/908], Loss: 0.2121\n",
      "Epoch [46/50], Step [500/908], Loss: 0.2136\n",
      "Epoch [46/50], Step [600/908], Loss: 0.2039\n",
      "Epoch [46/50], Step [700/908], Loss: 0.2124\n",
      "Epoch [46/50], Step [800/908], Loss: 0.2020\n",
      "Epoch [46/50], Step [900/908], Loss: 0.2184\n",
      "learning_rate: 0.000001\n",
      "Epoch [47/50], Step [100/908], Loss: 0.2367\n",
      "Epoch [47/50], Step [200/908], Loss: 0.2098\n",
      "Epoch [47/50], Step [300/908], Loss: 0.2104\n",
      "Epoch [47/50], Step [400/908], Loss: 0.2120\n",
      "Epoch [47/50], Step [500/908], Loss: 0.2135\n",
      "Epoch [47/50], Step [600/908], Loss: 0.2039\n",
      "Epoch [47/50], Step [700/908], Loss: 0.2124\n",
      "Epoch [47/50], Step [800/908], Loss: 0.2020\n",
      "Epoch [47/50], Step [900/908], Loss: 0.2184\n",
      "learning_rate: 0.000001\n",
      "Epoch [48/50], Step [100/908], Loss: 0.2367\n",
      "Epoch [48/50], Step [200/908], Loss: 0.2098\n",
      "Epoch [48/50], Step [300/908], Loss: 0.2104\n",
      "Epoch [48/50], Step [400/908], Loss: 0.2120\n",
      "Epoch [48/50], Step [500/908], Loss: 0.2135\n",
      "Epoch [48/50], Step [600/908], Loss: 0.2039\n",
      "Epoch [48/50], Step [700/908], Loss: 0.2124\n",
      "Epoch [48/50], Step [800/908], Loss: 0.2020\n",
      "Epoch [48/50], Step [900/908], Loss: 0.2184\n",
      "learning_rate: 0.000001\n",
      "Epoch [49/50], Step [100/908], Loss: 0.2367\n",
      "Epoch [49/50], Step [200/908], Loss: 0.2098\n",
      "Epoch [49/50], Step [300/908], Loss: 0.2104\n",
      "Epoch [49/50], Step [400/908], Loss: 0.2120\n",
      "Epoch [49/50], Step [500/908], Loss: 0.2135\n",
      "Epoch [49/50], Step [600/908], Loss: 0.2039\n",
      "Epoch [49/50], Step [700/908], Loss: 0.2124\n",
      "Epoch [49/50], Step [800/908], Loss: 0.2020\n",
      "Epoch [49/50], Step [900/908], Loss: 0.2184\n",
      "learning_rate: 0.000001\n",
      "Epoch [50/50], Step [100/908], Loss: 0.2367\n",
      "Epoch [50/50], Step [200/908], Loss: 0.2098\n",
      "Epoch [50/50], Step [300/908], Loss: 0.2104\n",
      "Epoch [50/50], Step [400/908], Loss: 0.2120\n",
      "Epoch [50/50], Step [500/908], Loss: 0.2135\n",
      "Epoch [50/50], Step [600/908], Loss: 0.2039\n",
      "Epoch [50/50], Step [700/908], Loss: 0.2124\n",
      "Epoch [50/50], Step [800/908], Loss: 0.2020\n",
      "Epoch [50/50], Step [900/908], Loss: 0.2183\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "running_loss = 0.0\n",
    "lr_update_step = 10\n",
    "log_loss_step = 100\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer = adjust_learning_rate(optimizer, epoch, learning_rate, lr_update_step)\n",
    "    for i, (X_, y_) in enumerate(train_loader):  \n",
    "        X_ = X_.to(device)\n",
    "        y_ = y_.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        preds_y_ = model(X_)\n",
    "        loss = criterion(preds_y_, y_.view(-1, 1))\n",
    "        # print(\"preds_y_: \", preds_y_)\n",
    "        # print(\"preds_y_.shape\", preds_y_.shape)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if (i+1) % log_loss_step == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {running_loss/log_loss_step:.4f}')\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds_y_:  tensor([[0., 0., 1., 1., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  86\n",
      "n_samples:  100\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 1., 0.]], device='cuda:0')\n",
      "n_correct:  178\n",
      "n_samples:  200\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  268\n",
      "n_samples:  300\n",
      "preds_y_:  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 1., 1., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  355\n",
      "n_samples:  400\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 1., 1., 0., 0.]], device='cuda:0')\n",
      "n_correct:  444\n",
      "n_samples:  500\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 1., 1., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  529\n",
      "n_samples:  600\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 1., 0., 1., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  618\n",
      "n_samples:  700\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
      "y_:  tensor([[1., 0., 1., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
      "n_correct:  705\n",
      "n_samples:  800\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  799\n",
      "n_samples:  900\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 1., 1.]], device='cuda:0')\n",
      "n_correct:  891\n",
      "n_samples:  1000\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  983\n",
      "n_samples:  1100\n",
      "preds_y_:  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
      "n_correct:  1073\n",
      "n_samples:  1200\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  1166\n",
      "n_samples:  1300\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  1255\n",
      "n_samples:  1400\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
      "n_correct:  1345\n",
      "n_samples:  1500\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 1., 1., 0., 0.]], device='cuda:0')\n",
      "n_correct:  1431\n",
      "n_samples:  1600\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  1522\n",
      "n_samples:  1700\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 1., 1., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 1., 1., 0., 0.]], device='cuda:0')\n",
      "n_correct:  1621\n",
      "n_samples:  1800\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 1., 1., 0., 1., 0.]], device='cuda:0')\n",
      "n_correct:  1711\n",
      "n_samples:  1900\n",
      "preds_y_:  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  1806\n",
      "n_samples:  2000\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  1898\n",
      "n_samples:  2100\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  1990\n",
      "n_samples:  2200\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  2079\n",
      "n_samples:  2300\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
      "n_correct:  2171\n",
      "n_samples:  2400\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  2265\n",
      "n_samples:  2500\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
      "n_correct:  2357\n",
      "n_samples:  2600\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  2449\n",
      "n_samples:  2700\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 1., 1., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  2532\n",
      "n_samples:  2800\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  2619\n",
      "n_samples:  2900\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  2709\n",
      "n_samples:  3000\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 1., 0.]], device='cuda:0')\n",
      "n_correct:  2800\n",
      "n_samples:  3100\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  2891\n",
      "n_samples:  3200\n",
      "preds_y_:  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
      "n_correct:  2984\n",
      "n_samples:  3300\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  3071\n",
      "n_samples:  3400\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
      "n_correct:  3165\n",
      "n_samples:  3500\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  3256\n",
      "n_samples:  3600\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  3351\n",
      "n_samples:  3700\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  3444\n",
      "n_samples:  3800\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  3534\n",
      "n_samples:  3900\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  3627\n",
      "n_samples:  4000\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  3722\n",
      "n_samples:  4100\n",
      "preds_y_:  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
      "n_correct:  3818\n",
      "n_samples:  4200\n",
      "preds_y_:  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[1., 0., 1., 0., 1., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  3910\n",
      "n_samples:  4300\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
      "n_correct:  4004\n",
      "n_samples:  4400\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 1., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
      "n_correct:  4095\n",
      "n_samples:  4500\n",
      "preds_y_:  tensor([[0., 0., 1., 1., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
      "n_correct:  4187\n",
      "n_samples:  4600\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 1., 0.]], device='cuda:0')\n",
      "n_correct:  4275\n",
      "n_samples:  4700\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 1., 1., 0., 0.]], device='cuda:0')\n",
      "n_correct:  4363\n",
      "n_samples:  4800\n",
      "preds_y_:  tensor([[0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
      "n_correct:  4454\n",
      "n_samples:  4900\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  4547\n",
      "n_samples:  5000\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  4641\n",
      "n_samples:  5100\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  4731\n",
      "n_samples:  5200\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 1.]], device='cuda:0')\n",
      "n_correct:  4820\n",
      "n_samples:  5300\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  4914\n",
      "n_samples:  5400\n",
      "preds_y_:  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  5006\n",
      "n_samples:  5500\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  5097\n",
      "n_samples:  5600\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  5192\n",
      "n_samples:  5700\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  5286\n",
      "n_samples:  5800\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  5368\n",
      "n_samples:  5900\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 1., 1., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  5462\n",
      "n_samples:  6000\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  5550\n",
      "n_samples:  6100\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  5648\n",
      "n_samples:  6200\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  5734\n",
      "n_samples:  6300\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  5832\n",
      "n_samples:  6400\n",
      "preds_y_:  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 1., 1., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  5923\n",
      "n_samples:  6500\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 1., 0.]], device='cuda:0')\n",
      "n_correct:  6013\n",
      "n_samples:  6600\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  6109\n",
      "n_samples:  6700\n",
      "preds_y_:  tensor([[0., 0., 1., 1., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
      "n_correct:  6199\n",
      "n_samples:  6800\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[1., 0., 0., 1., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
      "n_correct:  6292\n",
      "n_samples:  6900\n",
      "preds_y_:  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  6384\n",
      "n_samples:  7000\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  6479\n",
      "n_samples:  7100\n",
      "preds_y_:  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  6567\n",
      "n_samples:  7200\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  6660\n",
      "n_samples:  7300\n",
      "preds_y_:  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  6751\n",
      "n_samples:  7400\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[1., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  6840\n",
      "n_samples:  7500\n",
      "preds_y_:  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
      "n_correct:  6933\n",
      "n_samples:  7600\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  7022\n",
      "n_samples:  7700\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  7117\n",
      "n_samples:  7800\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  7207\n",
      "n_samples:  7900\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  7298\n",
      "n_samples:  8000\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  7390\n",
      "n_samples:  8100\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  7485\n",
      "n_samples:  8200\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  7576\n",
      "n_samples:  8300\n",
      "preds_y_:  tensor([[0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[1., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
      "n_correct:  7669\n",
      "n_samples:  8400\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  7761\n",
      "n_samples:  8500\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  7858\n",
      "n_samples:  8600\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  7952\n",
      "n_samples:  8700\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  8043\n",
      "n_samples:  8800\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  8135\n",
      "n_samples:  8900\n",
      "preds_y_:  tensor([[0., 1., 0., 1., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 1., 0., 1., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  8225\n",
      "n_samples:  9000\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  8317\n",
      "n_samples:  9100\n",
      "preds_y_:  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  8412\n",
      "n_samples:  9200\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  8504\n",
      "n_samples:  9300\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  8598\n",
      "n_samples:  9400\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 1., 0.]], device='cuda:0')\n",
      "n_correct:  8685\n",
      "n_samples:  9500\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 1., 1., 0., 0., 0., 1., 0.]], device='cuda:0')\n",
      "n_correct:  8775\n",
      "n_samples:  9600\n",
      "preds_y_:  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[1., 1., 0., 1., 0., 0., 0., 0., 1., 0.]], device='cuda:0')\n",
      "n_correct:  8866\n",
      "n_samples:  9700\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  8962\n",
      "n_samples:  9800\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  9054\n",
      "n_samples:  9900\n",
      "preds_y_:  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  9145\n",
      "n_samples:  10000\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  9238\n",
      "n_samples:  10100\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
      "n_correct:  9328\n",
      "n_samples:  10200\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  9421\n",
      "n_samples:  10300\n",
      "preds_y_:  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  9509\n",
      "n_samples:  10400\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  9601\n",
      "n_samples:  10500\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  9691\n",
      "n_samples:  10600\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 1.]], device='cuda:0')\n",
      "n_correct:  9783\n",
      "n_samples:  10700\n",
      "preds_y_:  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  9870\n",
      "n_samples:  10800\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  9957\n",
      "n_samples:  10900\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  10049\n",
      "n_samples:  11000\n",
      "preds_y_:  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 1., 1., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  10138\n",
      "n_samples:  11100\n",
      "preds_y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "n_correct:  10224\n",
      "n_samples:  11198\n",
      "Accuracy of the network on the 10000 test images: 91.30201821753884 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model -> no need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for X_, y_ in test_loader:\n",
    "        X_.to(device)\n",
    "        y_.to(device)\n",
    "        output = model(X_)\n",
    "        # max returns (value ,index)\n",
    "        preds_y_ = torch.round(output)\n",
    "        print(\"preds_y_: \", torch.transpose(preds_y_[:10], 0, 1))\n",
    "        print(\"y_: \", torch.transpose(y_.view(-1,1)[:10], 0, 1))\n",
    "        # break\n",
    "        n_samples += y_.shape[0]\n",
    "        n_correct += (preds_y_ == y_.view(-1,1)).sum().item()\n",
    "        print('n_correct: ', n_correct)\n",
    "        print('n_samples: ', n_samples)\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the 10000 test images: {acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch: 5 -> acc: 91.26%\n",
    "# epoch: 50 -> acc: 90.7%\n",
    "# epoch: 1000 -> acc: 90.8%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "case_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
