{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from models.LSTM import LSTM\n",
    "from models.RNN import RNN\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import Dataset\n",
    "import os\n",
    "from torchsummary import summary\n",
    "from tools.adjust_learning_rate import adjust_learning_rate\n",
    "from tools.train import train\n",
    "from tools.test import test\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import wandb\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"last_expr\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of negative sequence array (OHE):  (100000, 10, 312)\n",
      "Shape of positive sequence array (OHE):  (11979, 10, 312)\n",
      "Shape of negative sequence array:  (100000, 10)\n",
      "Shape of positive sequence array:  (11979, 10)\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load 3D numpy matrices (user, time, transaction type)\n",
    "ns = np.load('data/neg_sequences.npy')\n",
    "ps = np.load('data/pos_sequences.npy')\n",
    "\n",
    "transaction_size = ns.shape[-1]\n",
    "\n",
    "# Take a look at the given data with OHE (one-hot encodings)\n",
    "print('Shape of negative sequence array (OHE): ', ns.shape)\n",
    "print('Shape of positive sequence array (OHE): ', ps.shape)\n",
    "\n",
    "# Convert one-hot encodings to integers:\n",
    "ns = np.argmax(ns, axis=2)\n",
    "ps = np.argmax(ps, axis=2)\n",
    "\n",
    "# Take a look at the given data\n",
    "print('Shape of negative sequence array: ', ns.shape)\n",
    "print('Shape of positive sequence array: ', ps.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label the data\n",
    "ns_label = np.zeros_like(ns[:,0])\n",
    "ps_label = np.ones_like(ps[:,0])\n",
    "\n",
    "# Concetenate positive sequences with negative sequences regarding users with correponding labels (axis=0)\n",
    "X = np.concatenate((ns, ps), axis=0)\n",
    "y = np.concatenate((ns_label, ps_label), axis=0) \n",
    "\n",
    "# Shuffle data and labels, for reproductivity set random_state=0\n",
    "# dataset, labels = shuffle(dataset, labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train, test and validation ratios\n",
    "train_ratio = 0.8\n",
    "test_ratio = 0.1\n",
    "val_ratio = 0.1\n",
    "\n",
    "# Split the data / Shuffle it and maintain class balance\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_ratio, random_state=42, shuffle=True)\n",
    "\n",
    "# Further split train_data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=val_ratio, random_state=42, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (90702, 10)  - y_train.shape:  (90702,)\n",
      "X_test.shape:  (11198, 10)  - y_test.shape:  (11198,)\n",
      "X_val.shape:  (10079, 10)  - y_val.shape:  (10079,)\n"
     ]
    }
   ],
   "source": [
    "# Print train, test and validation dataset and label shapes\n",
    "print('X_train.shape: ', X_train.shape, ' - y_train.shape: ', y_train.shape)\n",
    "print('X_test.shape: ', X_test.shape, ' - y_test.shape: ', y_test.shape)\n",
    "print('X_val.shape: ', X_val.shape, ' - y_val.shape: ', y_val.shape)\n",
    "\n",
    "# Convert numpy arrays to torch.tensor\n",
    "X_train, y_train = torch.from_numpy(X_train), torch.from_numpy(y_train)\n",
    "X_train, y_train = X_train.to(device, dtype=torch.int32), y_train.to(device, dtype=torch.float32)\n",
    "X_test, y_test = torch.from_numpy(X_test), torch.from_numpy(y_test)\n",
    "X_test, y_test = X_test.to(device, dtype=torch.int32), y_test.to(device, dtype=torch.float32)\n",
    "X_val, y_val = torch.from_numpy(X_val), torch.from_numpy(y_val)\n",
    "X_val, y_val = X_val.to(device, dtype=torch.int32), y_val.to(device, dtype=torch.float32)\n",
    "\n",
    "# Create a custom dataset\n",
    "train_dataset = Dataset(X_train, y_train, device)\n",
    "test_dataset = Dataset(X_test, y_test, device)\n",
    "val_dataset = Dataset(X_val, y_val, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33monat-inak\u001b[0m (\u001b[33monat-inak-\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/onatinak/workspace/transaction_analysis/wandb/run-20240629_224337-bdcnjexl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/onat-inak-/RNN-Classifier/runs/bdcnjexl' target=\"_blank\">autumn-blaze-57</a></strong> to <a href='https://wandb.ai/onat-inak-/RNN-Classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/onat-inak-/RNN-Classifier' target=\"_blank\">https://wandb.ai/onat-inak-/RNN-Classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/onat-inak-/RNN-Classifier/runs/bdcnjexl' target=\"_blank\">https://wandb.ai/onat-inak-/RNN-Classifier/runs/bdcnjexl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding_layer): Embedding(312, 32)\n",
       "  (rnn): RNN(32, 64, batch_first=True)\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=1, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############\n",
    "##### RNN #####\n",
    "###############\n",
    "\n",
    "# Initialize W&B \n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project='RNN-Classifier',\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config= dict(\n",
    "    batch_size = 100,\n",
    "    transaction_size = transaction_size,\n",
    "    embedding_dim = 32,\n",
    "    hidden_dim = 64,\n",
    "    num_layers = 1,\n",
    "    device = device,\n",
    "    batch_first = True,\n",
    "    fc_hidden_dim = 128,\n",
    "    num_classes = 1,\n",
    "    num_epochs = 1,\n",
    "    learning_rate = 1e-3,\n",
    "    weight_decay = 0.0, \n",
    "    lr_update_step = 10,\n",
    "    log_step = 100,\n",
    "    lr_step_decay = False,\n",
    "    )\n",
    ")\n",
    "# initialize config\n",
    "config = wandb.config\n",
    "\n",
    "# Divide train and test dataset into batches\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False)\n",
    "\n",
    "# Check whether data is splitted correctly -> X_.shape: (batch, seq, encoding), y_.shape: (batch)\n",
    "# for i, (X_, y_) in enumerate(train_loader): \n",
    "#     print(X_.shape, y_.shape)\n",
    "#     print(X_[:10,:])\n",
    "#     print(y_[:10])\n",
    "#     break\n",
    "\n",
    "model = RNN(config.transaction_size, config.embedding_dim, config.hidden_dim, config.num_layers, config.device,\n",
    "            num_classes = config.num_classes, batch_first = config.batch_first, fc_hidden_dim = config.fc_hidden_dim)\n",
    "model.to(device)\n",
    "\n",
    "# for i, (X_, y_) in enumerate(train_loader):\n",
    "#     out = model(X_)\n",
    "#     break\n",
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         # print (name, param.data)\n",
    "#         print (name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LSTM settings\n",
    "# embedding_dim = 64\n",
    "# hidden_dim = 64\n",
    "# transaction_size = 312\n",
    "# num_layers = 2\n",
    "\n",
    "# # parameter setting\n",
    "# num_epochs = 50\n",
    "# batch_size = 100\n",
    "# use_gpu = (device.type == 'cuda')\n",
    "# learning_rate = 0.01\n",
    "\n",
    "# # Divide training dataset into batches\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# # Check whether data is splitted correctly -> X_.shape: (batch, seq, encoding), y_.shape: (batch)\n",
    "# for i, (X_, y_) in enumerate(train_loader): \n",
    "#     print(X_.shape, y_.shape)\n",
    "#     print(i)\n",
    "\n",
    "# model = LSTM(embedding_dim, hidden_dim, transaction_size, num_layers, batch_size, use_gpu)\n",
    "\n",
    "# model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate, betas=(0.9, 0.999),\n",
    "                             eps=1e-8, weight_decay=config.weight_decay, amsgrad=False)  \n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a56f58629a443b5814152428788f72c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [100/908], Loss: 0.3504\n",
      "learning_rate:  0.001\n",
      "Loss after 100 batches: 0.350\n",
      "Epoch [1/1], Step [200/908], Loss: 0.2510\n",
      "learning_rate:  0.001\n",
      "Loss after 200 batches: 0.251\n",
      "Epoch [1/1], Step [300/908], Loss: 0.2459\n",
      "learning_rate:  0.001\n",
      "Loss after 300 batches: 0.246\n",
      "Epoch [1/1], Step [400/908], Loss: 0.2468\n",
      "learning_rate:  0.001\n",
      "Loss after 400 batches: 0.247\n",
      "Epoch [1/1], Step [500/908], Loss: 0.2445\n",
      "learning_rate:  0.001\n",
      "Loss after 500 batches: 0.245\n",
      "Epoch [1/1], Step [600/908], Loss: 0.2303\n",
      "learning_rate:  0.001\n",
      "Loss after 600 batches: 0.230\n",
      "Epoch [1/1], Step [700/908], Loss: 0.2352\n",
      "learning_rate:  0.001\n",
      "Loss after 700 batches: 0.235\n",
      "Epoch [1/1], Step [800/908], Loss: 0.2301\n",
      "learning_rate:  0.001\n",
      "Loss after 800 batches: 0.230\n",
      "Epoch [1/1], Step [900/908], Loss: 0.2395\n",
      "learning_rate:  0.001\n",
      "Loss after 900 batches: 0.240\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train(model, train_loader, criterion, optimizer, scheduler, config)\n",
    "\n",
    "\n",
    "\n",
    "# Train the model\n",
    "# running_loss = 0.0\n",
    "# lr_update_step = 10\n",
    "# log_loss_step = 100\n",
    "\n",
    "# n_total_steps = len(train_loader)\n",
    "# wandb.watch(model, criterion, log=\"all\", log_freq=100)\n",
    "# for epoch in range(config.num_epochs):\n",
    "#     optimizer = adjust_learning_rate(optimizer, epoch, config.learning_rate, lr_update_step)\n",
    "#     for i, (X_, y_) in enumerate(train_loader):  \n",
    "#         X_ = X_.to(device)\n",
    "#         y_ = y_.to(device)\n",
    "        \n",
    "#         # Forward pass\n",
    "#         preds_y_ = model(X_)\n",
    "#         loss = criterion(preds_y_, y_.view(-1, 1))\n",
    "#         # print(\"preds_y_: \", preds_y_)\n",
    "#         # print(\"preds_y_.shape\", preds_y_.shape)\n",
    "        \n",
    "#         # Backward and optimize\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         running_loss += loss.item()\n",
    "        \n",
    "#         if (i+1) % log_loss_step == 0:\n",
    "#             print (f'Epoch [{epoch+1}/{config.num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {running_loss/log_loss_step:.4f}')\n",
    "#             running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  tensor([[0., 0., 1., 1., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 1., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 1., 1., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 1., 1., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 1., 0., 1., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
      "y_:  tensor([[1., 0., 1., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 1., 1.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 1., 1., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 1., 1., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 1., 1., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 1., 1., 0., 1., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 1., 1., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 1., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
      "y_:  tensor([[1., 0., 1., 0., 1., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 1., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 1., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 1., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 1., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 1., 1., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 1.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 1., 1., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 1., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[1., 0., 0., 1., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[1., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 1., 0., 0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[1., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 1., 0., 1., 0., 0., 0., 0., 1., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 1., 0., 1., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 1., 1., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 1., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 1., 1., 0., 0., 0., 1., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 1., 0.]], device='cuda:0')\n",
      "y_:  tensor([[1., 1., 0., 1., 0., 0., 0., 0., 1., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 1.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 1., 0., 0., 1., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 1., 1., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "predicted:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "y_:  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "Accuracy of the model on the 11198 transactions in test data: 90.926951%\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'TorchHistory.add_log_parameters_hook.<locals>.<lambda>'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Test the model -> no need to compute gradients (for memory efficiency)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Test the model -> no need to compute gradients (for memory efficiency)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#     n_correct = 0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#     acc = 100.0 * n_correct / n_samples\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#     print(f'Accuracy of the network on the 10000 test images: {acc} %')\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/transaction_analysis/tools/test.py:25\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(model, test_loader, device)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Save the model in the exchangeable ONNX format\u001b[39;00m\n\u001b[1;32m     24\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexperiments/RNN/model_state.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexperiments/RNN/model.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m wandb\u001b[38;5;241m.\u001b[39munwatch()\n\u001b[1;32m     27\u001b[0m wandb\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexperiments/RNN/model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/case_study/lib/python3.8/site-packages/torch/serialization.py:628\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 628\u001b[0m         \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/case_study/lib/python3.8/site-packages/torch/serialization.py:840\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    838\u001b[0m pickler \u001b[38;5;241m=\u001b[39m pickle_module\u001b[38;5;241m.\u001b[39mPickler(data_buf, protocol\u001b[38;5;241m=\u001b[39mpickle_protocol)\n\u001b[1;32m    839\u001b[0m pickler\u001b[38;5;241m.\u001b[39mpersistent_id \u001b[38;5;241m=\u001b[39m persistent_id\n\u001b[0;32m--> 840\u001b[0m \u001b[43mpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    841\u001b[0m data_value \u001b[38;5;241m=\u001b[39m data_buf\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m    842\u001b[0m zip_file\u001b[38;5;241m.\u001b[39mwrite_record(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, data_value, \u001b[38;5;28mlen\u001b[39m(data_value))\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't pickle local object 'TorchHistory.add_log_parameters_hook.<locals>.<lambda>'"
     ]
    }
   ],
   "source": [
    "# Test the model -> no need to compute gradients (for memory efficiency)\n",
    "test(model, test_loader, device)\n",
    "\n",
    "# Test the model -> no need to compute gradients (for memory efficiency)\n",
    "# with torch.no_grad():\n",
    "#     n_correct = 0\n",
    "#     n_samples = 0\n",
    "#     for X_, y_ in test_loader:\n",
    "#         X_.to(device)\n",
    "#         y_.to(device)\n",
    "#         output = model(X_)\n",
    "#         # max returns (value ,index)\n",
    "#         preds_y_ = torch.round(output)\n",
    "#         print(\"preds_y_: \", torch.transpose(preds_y_[:10], 0, 1))\n",
    "#         print(\"y_: \", torch.transpose(y_.view(-1,1)[:10], 0, 1))\n",
    "#         # break\n",
    "#         n_samples += y_.shape[0]\n",
    "#         n_correct += (preds_y_ == y_.view(-1,1)).sum().item()\n",
    "#         print('n_correct: ', n_correct)\n",
    "#         print('n_samples: ', n_samples)\n",
    "\n",
    "#     acc = 100.0 * n_correct / n_samples\n",
    "#     print(f'Accuracy of the network on the 10000 test images: {acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "case_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
